{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize The Prediction Model With The Top n Words\n",
    "\n",
    "Using the data stored in `top_posts.csz.gz` this script will aim to make model that can predict the number of upvotes (likes) given all other data in the file excluding `number_of_upvotes`, `total_votes`, and `number_of_downvotes`.\n",
    "\n",
    "This script aims to help further optimize the actual Prediction Model script by finding the best value `n` where `n` is the best number of popular words to include as an `n`-length binary list for the feature vector. At the same time, this model finds the best `alpha` value for Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import nltk\n",
    "from csv import DictReader\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import Ridge\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dwolfson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dwolfson/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download a few needed packages for the nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug variables\n",
    "date = date.today().strftime(\"%b %d\")\n",
    "baseline = 0\n",
    "pred_mse = 0\n",
    "feature_list = []\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the MSE of a list of preditions & labels\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list the frequencies of a given title's Parts of Speech\n",
    "def parts_of_speech(title):\n",
    "    # Tokenize the words in the title\n",
    "    tokens = word_tokenize(title)\n",
    "    \n",
    "    # Turns each token into a pair with its value and Part of Speech label\n",
    "    # More Info Here: https://realpython.com/nltk-nlp-python/#tagging-parts-of-speech\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Map the generalized Parts of Speech to their frequency in the title\n",
    "    frequencies = {\n",
    "        \"Adjectives\":0,\n",
    "        \"Nouns\":0,\n",
    "        \"Adverbs\":0,\n",
    "        \"Pronouns\":0,\n",
    "        \"Verbs\":0,\n",
    "        \"Determiners\":0\n",
    "    }\n",
    "    \n",
    "    # Count the frequencies of each Part of Speech generalizing to 7 categories\n",
    "    for pair in pos:\n",
    "        if pair[1].startswith(\"JJ\"):\n",
    "            frequencies[\"Adjectives\"] += 1\n",
    "        elif pair[1].startswith(\"NN\"):\n",
    "            frequencies[\"Nouns\"] += 1\n",
    "        elif pair[1].startswith(\"RB\"):\n",
    "            frequencies[\"Adverbs\"] += 1\n",
    "        elif pair[1].startswith(\"PRP\"):\n",
    "            frequencies[\"Pronouns\"] += 1\n",
    "        elif pair[1].startswith(\"VB\"):\n",
    "            frequencies[\"Verbs\"] += 1\n",
    "        elif pair[1].startswith(\"DT\"):\n",
    "            frequencies[\"Determiners\"] += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return list(frequencies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a one-hot encoding (OHE) of the hour of day, and weekday\n",
    "# OHE allows for encoding a n-length list of binary features in n - 1 space\n",
    "def one_hot_encoding_time(unixtime):\n",
    "    hour = [0] * 23\n",
    "    week = [0] * 6\n",
    "    \n",
    "    # Get the local time of the given unix timestamp\n",
    "    time = datetime.fromtimestamp(int(float(unixtime)))\n",
    "    \n",
    "    # One hot encode the hour (hour 0 is just a list of 0's)\n",
    "    # https://docs.python.org/3/library/datetime.html#datetime.datetime.hour\n",
    "    if time.hour != 0:\n",
    "        hour[time.hour - 1] = 1\n",
    "    \n",
    "    # One hot encode the weekday (day 0 is just a list of 0's)\n",
    "    # https://docs.python.org/3/library/datetime.html#datetime.date.weekday\n",
    "    if time.weekday() != 0:\n",
    "        week[time.weekday() - 1] = 1\n",
    "        \n",
    "    return hour + week\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function returns a list that represents the presence of popular words\n",
    "def popular_words(title, n, n_popular_words):\n",
    "    words = [0] * n\n",
    "    \n",
    "    for word in word_tokenize(title):\n",
    "        if word in n_popular_words:\n",
    "            words[n_popular_words.index(word)] = 1\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a feature vector for a given row of data\n",
    "def feature(datum, n, n_popular_words):\n",
    "    feat = [1]\n",
    "    \n",
    "    # Add a feature for the score (price of awards given)\n",
    "    feat.append(int(datum['score']))\n",
    "    \n",
    "    # Add a feature for the number of comments\n",
    "    feat.append(int(datum['number_of_comments']))\n",
    "    \n",
    "    # Add a feature for character length of title\n",
    "    feat.append(len(datum['title']))\n",
    "    \n",
    "    # Add a feature for word length of title\n",
    "    feat.append(len(word_tokenize(datum['title'])))\n",
    "    \n",
    "    # Add a binary feature for if the content is declared original (OC)\n",
    "    feat.append(1) if \"[oc]\" in datum['title'].lower() else feat.append(0)\n",
    "    \n",
    "    # Add features for the frequencies of generalized Parts of Speech\n",
    "    feat.extend(parts_of_speech(datum['title']))\n",
    "    \n",
    "    # Add features for the one-hot encoding of the Hour and Weekday\n",
    "    feat.extend(one_hot_encoding_time(datum['unixtime']))\n",
    "    \n",
    "    # Add feature list for the presence of any of the n-most popular words\n",
    "    feat.extend(popular_words(datum['title'], n, n_popular_words))\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "word_popularity = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and store each post as a list of dict elements\n",
    "with gzip.open('../data/top_posts.csv.gz', 'rt') as file:\n",
    "    csv_reader = DictReader(file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "        for word in word_tokenize(row['title']):\n",
    "            word_popularity[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_popularity = sorted(word_popularity.items(), key=lambda item: item[1], reverse=True)\n",
    "word_popularity = [pair[0] for pair in word_popularity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will store a list of MSE and their respective n\n",
    "n_performance = []\n",
    "lambdas = [0, 0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=3.26279e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=3.26279e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=3.26279e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=3.26279e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=3.26278e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=3.26278e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# Find the best n value\n",
    "for n in range(0, 1000, 100):\n",
    "    # Debug to know how far the script is\n",
    "    print(n)  \n",
    "      \n",
    "    # X is the list of all feature vectors\n",
    "    X = []\n",
    "    # y is the list of labels (correct values)\n",
    "    y = []\n",
    "    # List of the n-most popular words\n",
    "    n_popular_words = word_popularity[:n]\n",
    "    \n",
    "    for datum in data:\n",
    "        X.append(feature(datum, n, n_popular_words))\n",
    "        y.append(int(datum['number_of_upvotes']))\n",
    "    \n",
    "    # Split the datum between training (80%), validation (10%), and test (10%)\n",
    "    train = round(len(X) * 0.8)\n",
    "    valid = train + round(len(X) * 0.1)\n",
    "    tests = train + round(len(X) * 0.1)\n",
    "    \n",
    "    X_train = X[:train]\n",
    "    X_valid = X[train:valid]\n",
    "    X_tests = X[valid:]\n",
    "\n",
    "    y_train = y[:train]\n",
    "    y_valid = y[train:valid]\n",
    "    y_tests = y[valid:]\n",
    "    \n",
    "    # Intialize and fit the model to the training datas\n",
    "    model = Ridge(1.0, fit_intercept=False)\n",
    "    \n",
    "    # Try different alpha values for Ridge Regression\n",
    "    for alpha in lambdas:\n",
    "        model.set_params(alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        # Test model on validation\n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        n_performance.append((MSE(y_valid_pred, y_valid), n, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Pair: (139794359.08308473, 600, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Report the best MSE and n\n",
    "best_pair = min(n_performance, key = lambda x: x[0])\n",
    "print(\"Best Pair: {}\".format(best_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(144666612.36568236, 0, 0),\n",
       " (144666611.2953804, 0, 0.001),\n",
       " (144666601.66258094, 0, 0.01),\n",
       " (144666505.32726023, 0, 0.1),\n",
       " (144665541.2440276, 0, 1),\n",
       " (144655830.0795116, 0, 10),\n",
       " (144553767.74233425, 0, 100),\n",
       " (143486990.92661342, 0, 1000),\n",
       " (145941030.4527238, 100, 0),\n",
       " (145941026.06890044, 100, 0.001),\n",
       " (145940986.6149597, 100, 0.01),\n",
       " (145940592.12177563, 100, 0.1),\n",
       " (145936651.39476955, 100, 1),\n",
       " (145897498.9800274, 100, 10),\n",
       " (145519397.08860675, 100, 100),\n",
       " (142488273.04050204, 100, 1000),\n",
       " (145444486.1367397, 200, 0),\n",
       " (145444481.1469494, 200, 0.001),\n",
       " (145444436.24238572, 200, 0.01),\n",
       " (145443987.54322547, 200, 0.1),\n",
       " (145439530.77721465, 200, 1),\n",
       " (145396269.88762012, 200, 10),\n",
       " (144989620.21423835, 200, 100),\n",
       " (141950481.80758524, 200, 1000),\n",
       " (145227573.5781384, 300, 0),\n",
       " (145227565.99832186, 300, 0.001),\n",
       " (145227497.78565672, 300, 0.01),\n",
       " (145226816.21644714, 300, 0.1),\n",
       " (145220050.82917964, 300, 1),\n",
       " (145155268.00705808, 300, 10),\n",
       " (144615886.31820154, 300, 100),\n",
       " (141489379.7583914, 300, 1000),\n",
       " (144554479.6939235, 400, 0),\n",
       " (144554470.9740207, 400, 0.001),\n",
       " (144554392.50252303, 400, 0.01),\n",
       " (144553608.53374934, 400, 0.1),\n",
       " (144545835.8424808, 400, 1),\n",
       " (144471816.20018062, 400, 10),\n",
       " (143869959.83901224, 400, 100),\n",
       " (140819571.79408982, 400, 1000),\n",
       " (151117209.26236507, 500, 0),\n",
       " (151115723.21428332, 500, 0.001),\n",
       " (151102378.3221012, 500, 0.01),\n",
       " (150971794.00601882, 500, 0.1),\n",
       " (149902605.39171243, 500, 1),\n",
       " (146640059.0615569, 500, 10),\n",
       " (144483217.99015024, 500, 100),\n",
       " (140823169.9975524, 500, 1000),\n",
       " (150382354.50172633, 600, 0),\n",
       " (150380794.7663312, 600, 0.001),\n",
       " (150366788.19994107, 600, 0.01),\n",
       " (150229733.5611807, 600, 0.1),\n",
       " (149107817.49279058, 600, 1),\n",
       " (145674987.26126063, 600, 10),\n",
       " (143225663.91963157, 600, 100),\n",
       " (139794359.08308473, 600, 1000),\n",
       " (4.32861484884773e+36, 700, 0),\n",
       " (148910139.61030108, 700, 0.001),\n",
       " (148899239.8645843, 700, 0.01),\n",
       " (148793801.03542468, 700, 0.1),\n",
       " (147999240.31777257, 700, 1),\n",
       " (145954639.76914448, 700, 10),\n",
       " (143999346.37949768, 700, 100),\n",
       " (140027772.1148191, 700, 1000),\n",
       " (4.1123616009156483e+37, 800, 0),\n",
       " (150391413.45147395, 800, 0.001),\n",
       " (150379907.75530228, 800, 0.01),\n",
       " (150268815.30125764, 800, 0.1),\n",
       " (149443741.6022435, 800, 1),\n",
       " (147385790.1890233, 800, 10),\n",
       " (145113617.16017574, 800, 100),\n",
       " (140312870.53891167, 800, 1000),\n",
       " (2.5957832581473923e+36, 900, 0),\n",
       " (151718245.2377585, 900, 0.001),\n",
       " (151705289.02956718, 900, 0.01),\n",
       " (151580620.26598012, 900, 0.1),\n",
       " (150679937.51063493, 900, 1),\n",
       " (148591136.29531193, 900, 10),\n",
       " (145974637.67303234, 900, 100),\n",
       " (140461603.3129066, 900, 1000)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_performance"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
